{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"talkingdata-adtracking-fraud-detection/mnt/ssd/kaggle-talkingdata2/competition_files/train.csv\", \n",
    "                      nrows=100000, parse_dates=['click_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time attributed_time  \\\n",
       "0   83230    3       1  13      379 2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379 2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379 2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478 2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379 2017-11-06 14:35:08             NaN   \n",
       "\n",
       "   is_attributed  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['day'] = X_train['click_time'].dt.day.astype('uint8')\n",
    "X_train['hour'] = X_train['click_time'].dt.hour.astype('uint8')\n",
    "X_train['minute'] = X_train['click_time'].dt.minute.astype('uint8')\n",
    "X_train['second'] = X_train['click_time'].dt.second.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time attributed_time  \\\n",
       "0   83230    3       1  13      379 2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379 2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379 2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478 2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379 2017-11-06 14:35:08             NaN   \n",
       "\n",
       "   is_attributed  day  hour  minute  second  \n",
       "0              0    6    14      32      21  \n",
       "1              0    6    14      33      34  \n",
       "2              0    6    14      34      12  \n",
       "3              0    6    14      34      52  \n",
       "4              0    6    14      35       8  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTION_CATEGORIES = [        \n",
    "    # V1 Features #\n",
    "    ###############\n",
    "    ['ip'], ['app'], ['device'], ['os'], ['channel'],\n",
    "    \n",
    "    # V2 Features #\n",
    "    ###############\n",
    "    ['app', 'channel'],\n",
    "    ['app', 'os'],\n",
    "    ['app', 'device'],\n",
    "    \n",
    "    # V3 Features #\n",
    "    ###############\n",
    "    ['channel', 'os'],\n",
    "    ['channel', 'device'],\n",
    "    ['os', 'device']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Calculating confidence-weighted rate for: ['ip'].\n",
      "   Saving to: ip_confRate. Group Max /Mean / Median / Min: 610 / 6.51 / 3.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['app'].\n",
      "   Saving to: app_confRate. Group Max /Mean / Median / Min: 13280 / 847.46 / 5.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['device'].\n",
      "   Saving to: device_confRate. Group Max /Mean / Median / Min: 94397 / 1694.92 / 1.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['os'].\n",
      "   Saving to: os_confRate. Group Max /Mean / Median / Min: 23957 / 1052.63 / 67.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['channel'].\n",
      "   Saving to: channel_confRate. Group Max /Mean / Median / Min: 10582 / 751.88 / 188.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['app', 'channel'].\n",
      "   Saving to: app_channel_confRate. Group Max /Mean / Median / Min: 10015 / 315.46 / 24.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['app', 'os'].\n",
      "   Saving to: app_os_confRate. Group Max /Mean / Median / Min: 3236 / 65.83 / 6.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['app', 'device'].\n",
      "   Saving to: app_device_confRate. Group Max /Mean / Median / Min: 12455 / 471.7 / 2.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['channel', 'os'].\n",
      "   Saving to: channel_os_confRate. Group Max /Mean / Median / Min: 2540 / 28.66 / 5.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['channel', 'device'].\n",
      "   Saving to: channel_device_confRate. Group Max /Mean / Median / Min: 10250 / 342.47 / 7.0 / 1\n",
      ">> Calculating confidence-weighted rate for: ['os', 'device'].\n",
      "   Saving to: os_device_confRate. Group Max /Mean / Median / Min: 23217 / 462.96 / 8.0 / 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "freqs = {}\n",
    "for cols in ATTRIBUTION_CATEGORIES:\n",
    "    \n",
    "    # New feature name\n",
    "    new_feature = '_'.join(cols)+'_confRate'    \n",
    "    \n",
    "    # Perform the groupby\n",
    "    group_object = X_train.groupby(cols)\n",
    "    \n",
    "    # Group sizes    \n",
    "    group_sizes = group_object.size()\n",
    "    \n",
    "    log_group = np.log(100000) # 1000 views -> 60% confidence, 100 views -> 40% confidence \n",
    "    print(\">> Calculating confidence-weighted rate for: {}.\\n   Saving to: {}. Group Max /Mean / Median / Min: {} / {} / {} / {}\".format(\n",
    "        cols, new_feature, \n",
    "        group_sizes.max(), \n",
    "        np.round(group_sizes.mean(), 2),\n",
    "        np.round(group_sizes.median(), 2),\n",
    "        group_sizes.min()\n",
    "    ))\n",
    "    \n",
    "    # Aggregation function\n",
    "    def rate_calculation(x):\n",
    "        \"\"\"Calculate the attributed rate. Scale by confidence\"\"\"\n",
    "        rate = x.sum() / float(x.count())\n",
    "        conf = np.min([1, np.log(x.count()) / log_group])\n",
    "        return rate * conf\n",
    "    \n",
    "    # Perform the merge\n",
    "    X_train = X_train.merge(\n",
    "        group_object['is_attributed']. \\\n",
    "            apply(rate_calculation). \\\n",
    "            reset_index(). \\\n",
    "            rename( \n",
    "                index=str,\n",
    "                columns={'is_attributed': new_feature}\n",
    "            )[cols + [new_feature]],\n",
    "        on=cols, how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>app</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "      <th>attributed_time</th>\n",
       "      <th>is_attributed</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>app_confRate</th>\n",
       "      <th>device_confRate</th>\n",
       "      <th>os_confRate</th>\n",
       "      <th>channel_confRate</th>\n",
       "      <th>app_channel_confRate</th>\n",
       "      <th>app_os_confRate</th>\n",
       "      <th>app_device_confRate</th>\n",
       "      <th>channel_os_confRate</th>\n",
       "      <th>channel_device_confRate</th>\n",
       "      <th>os_device_confRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83230</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:32:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17357</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:33:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35810</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:34:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45745</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>478</td>\n",
       "      <td>2017-11-06 14:34:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>161007</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>379</td>\n",
       "      <td>2017-11-06 14:35:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ip  app  device  os  channel          click_time attributed_time  \\\n",
       "0   83230    3       1  13      379 2017-11-06 14:32:21             NaN   \n",
       "1   17357    3       1  19      379 2017-11-06 14:33:34             NaN   \n",
       "2   35810    3       1  13      379 2017-11-06 14:34:12             NaN   \n",
       "3   45745   14       1  13      478 2017-11-06 14:34:52             NaN   \n",
       "4  161007    3       1  13      379 2017-11-06 14:35:08             NaN   \n",
       "\n",
       "   is_attributed  day  hour  ...  app_confRate  device_confRate  os_confRate  \\\n",
       "0              0    6    14  ...      0.000296         0.001307     0.001149   \n",
       "1              0    6    14  ...      0.000296         0.001307     0.001389   \n",
       "2              0    6    14  ...      0.000296         0.001307     0.001149   \n",
       "3              0    6    14  ...      0.000685         0.001307     0.001149   \n",
       "4              0    6    14  ...      0.000296         0.001307     0.001149   \n",
       "\n",
       "   channel_confRate  app_channel_confRate  app_os_confRate  \\\n",
       "0               0.0                   0.0          0.00027   \n",
       "1               0.0                   0.0          0.00000   \n",
       "2               0.0                   0.0          0.00027   \n",
       "3               0.0                   0.0          0.00000   \n",
       "4               0.0                   0.0          0.00027   \n",
       "\n",
       "   app_device_confRate  channel_os_confRate  channel_device_confRate  \\\n",
       "0             0.000306                  0.0                      0.0   \n",
       "1             0.000306                  0.0                      0.0   \n",
       "2             0.000306                  0.0                      0.0   \n",
       "3             0.000698                  0.0                      0.0   \n",
       "4             0.000306                  0.0                      0.0   \n",
       "\n",
       "   os_device_confRate  \n",
       "0            0.001187  \n",
       "1            0.001429  \n",
       "2            0.001187  \n",
       "3            0.001187  \n",
       "4            0.001187  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = X_train['is_attributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labels = pd.get_dummies(list(X_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = X_train.drop(columns = ['is_attributed', 'click_time', 'attributed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_processed, X_labels, test_size = 0.1)\n",
    "\n",
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 2)\n",
      "(90000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output = y_train.shape[1]\n",
    "num_layers_0 = 13\n",
    "regularizer_rate = 0.1\n",
    "\n",
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder('float32',shape = (None,num_features), name='input_X')\n",
    "input_y = tf.placeholder('float32',shape = (None,num_classes), name='input_Y')\n",
    "\n",
    "# for dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    '0': tf.Variable(tf.random_normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features))))),\n",
    "    '1': tf.Variable(tf.random_normal([num_layers_0,num_output], stddev=(1/tf.sqrt(float(num_layers_0))))),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    '0': tf.Variable(tf.random_normal([num_layers_0])),\n",
    "    '1': tf.Variable(tf.random_normal([num_output])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing weights and biases\n",
    "hidden_output_0 = tf.nn.relu(tf.matmul(input_X,weights['0'])+biases['0'])\n",
    "hidden_output_0_0 = tf.nn.dropout(hidden_output_0, rate = 1-keep_prob)\n",
    "\n",
    "predicted_y = tf.sigmoid(tf.matmul(hidden_output_0_0,weights['1']) + biases['1'])\n",
    "\n",
    "\n",
    "\n",
    "# Defining the loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_y,labels=input_y)) \\\n",
    "+ regularizer_rate*(tf.reduce_sum(tf.square(biases['0'])))\n",
    "\n",
    "\n",
    "learning_rate = 0.005\n",
    "# Adam optimizer for finding the right weight\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss,var_list=[weights['0'], weights['1'],\n",
    "                                                                         biases['0'], biases['1']])\n",
    "\n",
    "# Metrics definition\n",
    "correct_prediction = tf.equal(tf.argmax(y_train,1), tf.argmax(predicted_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "batch_size = 500\n",
    "epochs = 100\n",
    "dropout = 0.4\n",
    "\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, Train loss: 0.49 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:1, Train loss: 0.95 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:2, Train loss: 0.37 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:3, Train loss: 0.32 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:4, Train loss: 0.32 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:5, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:6, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:7, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:8, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:9, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:10, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:11, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:12, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:13, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:14, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:15, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:16, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:17, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:18, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:19, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:20, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:21, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:22, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:23, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:24, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:25, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:26, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:27, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:28, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:29, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:30, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:31, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:32, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:33, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:34, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:35, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:36, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:37, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:38, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:39, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:40, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:41, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:42, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:43, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:44, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:45, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:46, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:47, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:48, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:49, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:50, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:51, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:52, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:53, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:54, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:55, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:56, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:57, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:58, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:59, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:60, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:61, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:62, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:63, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:64, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:65, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:66, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:67, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:68, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:69, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:70, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:71, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:72, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:73, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:74, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:75, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:76, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:77, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:78, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:79, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:80, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:81, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:82, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:83, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:84, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:85, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:86, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:87, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:88, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:89, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:90, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:91, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:92, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:93, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:94, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:95, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:96, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:97, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:98, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n",
      "Epoch:99, Train loss: 0.31 Train acc: 0.998, Test acc:0.998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):    \n",
    "    arr = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0,X_train.shape[0],batch_size):\n",
    "        s.run(optimizer, {input_X: X_train[arr[index:index+batch_size]], \n",
    "                          input_y: y_train[arr[index:index+batch_size]],\n",
    "                          keep_prob:dropout\n",
    "                          })\n",
    "    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:X_train, \n",
    "                                                         input_y: y_train,\n",
    "                                                         keep_prob:1\n",
    "                                                         }))\n",
    "    training_loss.append(s.run(loss, {input_X: X_train, \n",
    "                                      input_y: y_train,keep_prob:1}))\n",
    "    \n",
    "    # Evaluation of model\n",
    "    testing_accuracy.append(accuracy_score(y_test.argmax(1), \n",
    "                            s.run(predicted_y, {input_X: X_test,keep_prob:1}).argmax(1)))\n",
    "    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}, Test acc:{3:.3f}\".format(epoch, training_loss[epoch], training_accuracy[epoch],testing_accuracy[epoch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
